
<!DOCTYPE html>
<html lang="en"> 
<head>
<meta charset="utf-8">
<title>Iuliia Kotseruba
</title>
<meta name="description" content="{ description }">
<link rel="canonical" href="https://ykotseruba.github.io/">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<link rel="icon" type="image/svg+xml" href="/favicon.svg">
<style>
  body{font:300 1em cambria;padding:50px}
  a:visited,a:link,a:hover{color:#000}
  h3{font:300 1em cambria}
  h2{font:300 1.2em cambria}
  h1{font:300 2.2em cambria}
  dd{margin-inline-start:0px;margin-bottom:15px}

</style>
</head> 
<body>  
<header> 
<h1>Iuliia (Yulia) Kotseruba
</h1> 
<h2>PhD Candidate, York University
</h2> 

<p>
<img src="avatar.jpg" alt="IK" height="150"> 
</p>

<p>
I am a PhD student supervised by Prof. John K. Tsotsos and member of the <a href="http://jtl.lassonde.yorku.ca/">Lab for Active and Attentive Vision</a> at York University.<br>

I am interested in building AI systems inspired by knowledge about human vision and cognition for various applications, such as intelligent transportation, saliency prediction, and video game playing. My work focuses on applying domain knowledge, data analysis, and benchmarking to develop better models and identify open problems.
</p> 



<div class="wrapper"> 
<div> 
<h2>Links
</h2> 

<ul> 

  <li>
  <a href="https://scholar.google.com/citations?user=a-UOikoAAAAJ&hl=en">Google Scholar Profile</a>
  </li>

  <li>
  <a href="https://www.researchgate.net/profile/Yulia_Kotseruba">ResearchGate Profile</a>
  </li>

  <li>
  <a href="https://github.com/ykotseruba">Github</a>
  </li>

  <li>
  <a href="CV.pdf">CV</a>
  </li>

  <li>
  <a href="mailto:yulia84@yorku.ca">Email</a>
  </li>
</ul>
</div> 


<div class="wrapper"> 
  <div> 
  <h2>Projects</h2> 
    <ul> 
    <li>
    <a href="https://github.com/ykotseruba/attention_and_driving">Attention and Driving</a>
    <dt>
      <dd>A curated list of papers/code on how drivers observe the traffic scene</dd>
    </dt>
    </li> 
    <li>
    <a href="http://jtl.lassonde.yorku.ca/project/cognitive_architectures_survey/index.html">Cognitive Architectures
    </a>
    <dt>
      <dd>A survey of 84 cognitive architectures developed in the past 40 years</dd>
    </dt>
    </li> 
    <li> 
    Pedestrian Behavior Understanding
    <dt>
      <dd>Two datasets (<a href="https://github.com/ykotseruba/JAAD">JAAD</a> and <a href="https://github.com/aras62/PIE">PIE</a>) for studying pedestrian crossing behavior<br>
      Models for predicting trajectory (<a href="https://github.com/aras62/PIEPredict">PIEtraj</a>) and crossing action (<a href="https://github.com/aras62/SF-GRU">SF-GRU</a>,<a href="https://github.com/ykotseruba/PedestrianActionBenchmark">PCPA</a>)</dd>
    </dt>
    </li> 
    <li> 
    Odd-One-Out Benchmark
    <dt>
      <dd>A collection of <a href="http://data.nvision2.eecs.yorku.ca/P3O3/">synthetic and natural images</a> with odd-one-out (singleton) objects and <a href="https://github.com/ykotseruba/P3O3_metrics">metrics</a> for evaluating saliency algorithms</dd>
    </dt>
    </a>
    </li>
    <li> 
    <a href="https://github.com/TsotsosLab/STAR-FC">Saccade Generator for Static Images</a>
    <dt>
      <dd>A model for generating sequences of fixations for any image -- <a href="https://github.com/TsotsosLab/STAR-FC">STAR-FC</a>(C++) and <a href="https://github.com/ykotseruba/pySTAR-FC">pySTAR-FC</a> (Python)</dd>
    </dt>
    </a>
    </li>  
  </ul>
  </div> 
</div> 
 
</header> 
<main> 
<h2>Publications
</h2> 
<dd>See my <a href="https://scholar.google.com/citations?user=a-UOikoAAAAJ&hl=en">Google Scholar Profile</a> for a full list</dd>

<br>

<p style="text-align: right;">
Webpage template modified from <a href="https://glynnbird.com/">here</a>
</p>
</main>  
</body>
</html>