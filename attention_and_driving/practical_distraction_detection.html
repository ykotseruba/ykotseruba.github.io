<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="assets/css/tabulator/4.9/tabulator.min.css" rel="stylesheet">
		<link href="assets/css/tables.css" rel="stylesheet">
	</head>


	<body>

  <!-- Top navigation -->
<div class="topnav">

<a href="https://github.com/ykotseruba/attention_and_driving">Back to Github</a>
<a href="behavioral_studies.html">Behavioral</a>
<a href="#" class="active">Practical</a>
<a href="datasets_datasets.html">Datasets</a>
<a href="surveys_surveys.html">Surveys</a>


</div> 

<div class="topnav">

<a href="practical_scene_gaze.html">Scene gaze</a>
<a href="practical_in_vehicle_gaze.html">In-vehicle gaze</a>
<a href="#" class="active">Distraction detection</a>
<a href="practical_drowsiness_detection.html">Drowsiness detection</a>
<a href="practical_action_anticipation.html">Action anticipation</a>
<a href="practical_driver_awareness.html">Driver awareness</a>
<a href="practical_self_driving.html">Self-driving</a>
<a href="practical_factors.html">Factors</a>


</div> 

		<div id="example-table"></div>
						<script type="text/javascript" src="assets/js/tabulator/4.9/tabulator.min.js"></script>
		<script type="text/javascript">
	//sample data
	var tabledata = [
	{reference_link: "https://doi.org/10.1109/TITS.2021.3055545",bibtex: "<a href=\"all_bib.html#2021_T-ITS_Chen\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2021.3055545\">2021_T-ITS_Chen</a>",title: "Fine-Grained Detection of Driver Distraction Based on Neural Architecture Search",venue: "T-ITS",year: "2021",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "math quiz, emotional questions",visuomanual_distraction: "texting",observation: "5s",input: "D<sup>TC</sup>,  D<sup>RGB</sup>",output: "distraction type",dataset: "public: C42CN",recording_conditions: "simulator",location: "highway",distraction: "scheduled",metrics: "P, R, F1, ROC curve"},
{reference_link: "https://doi.org/10.1016/j.patcog.2021.107955",bibtex: "<a href=\"all_bib.html#2021_PR_Yang\">bib</a>",reference: "<a href=\"https://doi.org/10.1016/j.patcog.2021.107955\">2021_PR_Yang</a>",title: "Recognition of visual-related non-driving activities using a dual-camera monitoring system",venue: "PR",year: "2021",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "-",visuomanual_distraction: "reading book, phone, tablet, laptop",observation: "-",input: "D<sup>RGB</sup>",output: "distraction type",dataset: "private",recording_conditions: "on-road",location: "parked",distraction: "scheduled",metrics: "Acc"},
{reference_link: "https://doi.org/10.1109/TMC.2019.2962764",bibtex: "<a href=\"all_bib.html#2019_TMC_Fan\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TMC.2019.2962764\">2019_TMC_Fan</a>",title: "GazMon: Eye Gazing Enabled Driving Behavior Monitoring and Prediction",venue: "IEEE Transactions on Mobile Computing",year: "2019",visual_distraction: "-",manual_distraction: "eating, drinking",cognitive_distraction: "-",visuomanual_distraction: "cell phone, texting, reading, reaching",observation: "1-5s",input: "D<sup>RGB</sup>",output: "distraction type (1-8s into future, normal, using phone reaching, eating)",dataset: "private",recording_conditions: "on-road, simulator",location: "highway, urban",distraction: "scheduled",metrics: "Acc, P, R, F-score"},
{reference_link: "https://doi.org/10.1109/IROS.2018.8594305",bibtex: "<a href=\"all_bib.html#2018_IROS_Wang\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IROS.2018.8594305\">2018_IROS_Wang</a>",title: "Real-Time Workload Classification during Driving using HyperNetworks",venue: "IROS",year: "2018",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "visual n-back task",visuomanual_distraction: "-",observation: "5, 10, 20s",input: "GD",output: "driver status",dataset: "private",recording_conditions: "simulator",location: "highway",distraction: "scheduled",metrics: "P, R, F-score"},
{reference_link: "https://doi.org/10.1016/j.trf.2016.09.015",bibtex: "<a href=\"all_bib.html#2016_TransRes_Munoz\">bib</a>",reference: "<a href=\"https://doi.org/10.1016/j.trf.2016.09.015\">2016_TransRes_Munoz</a>",title: "Distinguishing patterns in drivers’ visual attention allocation using Hidden Markov Models",venue: "Transportation Research Part F",year: "2016",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "Voice-based HMI",visuomanual_distraction: "pressing a button, radio tuning",observation: "-",input: "GD",output: "driver status",dataset: "private",recording_conditions: "on-road",location: "highway",distraction: "scheduled",metrics: "Acc"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2506602",bibtex: "<a href=\"all_bib.html#2016_T-ITS_Liao\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2506602\">2016_T-ITS_Liao</a>",title: "Detection of Driver Cognitive Distraction: A Comparison Study of Stop-Controlled Intersection and Speed-Limited Highway",venue: "T-ITS",year: "2016",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "clock task",visuomanual_distraction: "-",observation: "-",input: "EV, GD",output: "driver status",dataset: "private",recording_conditions: "simulator",location: "highway, urban",distraction: "scheduled",metrics: "Acc, P, R, F1"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2493451",bibtex: "<a href=\"all_bib.html#2016_T-ITS_Li\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2493451\">2016_T-ITS_Li</a>",title: "Detecting Drivers’ Mirror-Checking Actions and Its Application to Maneuver and Secondary Task Recognition",venue: "T-ITS",year: "2016",visual_distraction: "gps following",manual_distraction: "-",cognitive_distraction: "conversation",visuomanual_distraction: "radio, gps entry,  taking a picture",observation: "2, 5s",input: "D<sup>RGB</sup>",output: "distraction type (radio, GPS-following, Phone, picture, conversation)",dataset: "private",recording_conditions: "on-road",location: "urban",distraction: "scheduled",metrics: "F1"},
{reference_link: "https://doi.org/10.1109/IVS.2016.7535416",bibtex: "<a href=\"all_bib.html#2016_IV_Liao\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2016.7535416\">2016_IV_Liao</a>",title: "Detection of Driver Cognitive Distraction: A Comparison Study of Stop-Controlled Intersection and Speed-Limited Highway",venue: "IV",year: "2016",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "clock task",visuomanual_distraction: "-",observation: "2s, 5s",input: "EV, GD, HP",output: "driver status",dataset: "private",recording_conditions: "simulator",location: "highway, urban",distraction: "scheduled",metrics: "Acc, F1"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2496157",bibtex: "<a href=\"all_bib.html#2015_T-ITS_Liu\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2496157\">2015_T-ITS_Liu</a>",title: "Driver Distraction Detection Using Semi-Supervised Machine Learning",venue: "T-ITS",year: "2015",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "sound counting",visuomanual_distraction: "-",observation: "10s",input: "HP, GD",output: "driver status",dataset: "private",recording_conditions: "on-road",location: "highway",distraction: "scheduled",metrics: "Acc, Sp, Se, F-score"},
{reference_link: "https://doi.org/10.1109/TITS.2014.2324414",bibtex: "<a href=\"all_bib.html#2015_T-ITS_Li\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2014.2324414\">2015_T-ITS_Li</a>",title: "Predicting Perceived Visual and Cognitive Distractions of Drivers With Multimodal Features",venue: "T-ITS",year: "2015",visual_distraction: "gps following",manual_distraction: "-",cognitive_distraction: "conversation",visuomanual_distraction: "radio, gps entry, phone talking, taking a picture",observation: "10s",input: "D<sup>RGB</sup>",output: "distraction type",dataset: "private",recording_conditions: "on-road",location: "urban",distraction: "scheduled",metrics: "P, R, F-score"},
{reference_link: "https://doi.org/10.1109/ITSC.2015.268",bibtex: "<a href=\"all_bib.html#2015_T-ITS_Braunagel\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2015.268\">2015_T-ITS_Braunagel</a>",title: "Driver-Activity Recognition in the Context of Conditionally Autonomous Driving",venue: "T-ITS",year: "2015",visual_distraction: "reading",manual_distraction: "-",cognitive_distraction: "-",visuomanual_distraction: "-",observation: "5s",input: "GD, HP",output: "distraction type",dataset: "private",recording_conditions: "simulator",location: "highway",distraction: "scheduled",metrics: "Acc, P, R, CM"},
{reference_link: "https://doi.org/10.1109/ITSC.2015.217",bibtex: "<a href=\"all_bib.html#2015_ITSC_Liu\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2015.217\">2015_ITSC_Liu</a>",title: "Cluster regularized extreme learning machine for detecting mixed-type distraction in driving",venue: "ITSC",year: "2015",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "sound counting",visuomanual_distraction: "visual search",observation: "10s",input: "GD, HP",output: "driver status",dataset: "private",recording_conditions: "simulator",location: "highway",distraction: "scheduled",metrics: "Acc, ER"},
{reference_link: "https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W11/papers/Seshadri_Driver_Cell_Phone_2015_CVPR_paper.pdf",bibtex: "<a href=\"all_bib.html#2015_CVPRW_Seshadri\">bib</a>",reference: "<a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W11/papers/Seshadri_Driver_Cell_Phone_2015_CVPR_paper.pdf\">2015_CVPRW_Seshadri</a>",title: "Driver Cell Phone Usage Detection on Strategic Highway Research Program (SHRP2) Face View Videos",venue: "CVPRW",year: "2015",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "talking on the phone",visuomanual_distraction: "-",observation: "1 frame",input: "D<sup>IR</sup>",output: "driver status",dataset: "public: SHRP2",recording_conditions: "on-road",location: "highway, urban",distraction: "scheduled",metrics: "Acc, ROC, VR, FAR, EER, AUC"},
{reference_link: "https://doi.org/10.1109/ITSC.2014.6957813",bibtex: "<a href=\"all_bib.html#2014_ITSC_Hirayama\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2014.6957813\">2014_ITSC_Hirayama</a>",title: "Analysis of Peripheral Vehicular Behavior in Driver’s Gaze Transition: Differences between Driver’s Neutral and Cognitive Distraction States",venue: "ITSC",year: "2014",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "voice-based playlist retrieval",visuomanual_distraction: "-",observation: "12s",input: "GD, EV",output: "driver status",dataset: "private",recording_conditions: "on-road",location: "highway",distraction: "scheduled",metrics: "Acc"},
{reference_link: "https://doi.org/10.1109/TITS.2013.2247760",bibtex: "<a href=\"all_bib.html#2013_T-ITS_Tango\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2013.2247760\">2013_T-ITS_Tango</a>",title: "Real-Time Detection System of Driver Distraction Using Machine Learning",venue: "T-ITS",year: "2013",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "-",visuomanual_distraction: "SuRT",observation: "1.8s",input: "GD, EV",output: "driver status",dataset: "private",recording_conditions: "on-road",location: "highway",distraction: "scheduled",metrics: "Acc"},
{reference_link: "https://doi.org/10.1201/9781315578156",bibtex: "<a href=\"all_bib.html#2013_DDI_Ahlstrom\">bib</a>",reference: "<a href=\"https://doi.org/10.1201/9781315578156\">2013_DDI_Ahlstrom</a>",title: "A Gaze-Based Driver Distraction Warning System and Its Effect on Visual Behavior",venue: "Driver Distraction and Inattention",year: "2013",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "-",visuomanual_distraction: "-",observation: "2s",input: "GD, EV",output: "driver status",dataset: "private",recording_conditions: "on-road",location: "highway, urban",distraction: "self-initiated",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/ITSC.2012.6338634",bibtex: "<a href=\"all_bib.html#2012_ITSC_Hirayama\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2012.6338634\">2012_ITSC_Hirayama</a>",title: "Detection of Driver Distraction based on Temporal Relationship between Eye-Gaze and Peripheral Vehicle Behavior",venue: "ITSC",year: "2012",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "voice-based playlist retrieval",visuomanual_distraction: "-",observation: "10s",input: "GD",output: "driver status",dataset: "private",recording_conditions: "on-road",location: "highway",distraction: "scheduled",metrics: "Acc"},
{reference_link: "https://doi.org/10.1109/TITS.2011.2119483",bibtex: "<a href=\"all_bib.html#2011_T-ITS_Wollmer\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2011.2119483\">2011_T-ITS_Wollmer</a>",title: "Online Driver Distraction Detection UsingLong Short-Term Memory",venue: "T-ITS",year: "2011",visual_distraction: "-",manual_distraction: "-",cognitive_distraction: "-",visuomanual_distraction: "radio, playlist retrieval, adjust volume, search phonebook, gps entry",observation: "3s",input: "HP, EV",output: "distraction type",dataset: "private",recording_conditions: "on-road",location: "rural",distraction: "scheduled",metrics: "Acc, P, R, F-score"},
	];

	var table = new Tabulator("#example-table", {
		height:700, // set height of table to enable virtual DOM
		data:tabledata, //load initial data into table
		layout:"fitColumns", //fit columns to width of table (optional)
		columns:[ //Define Table Columns
			{title:"Reference", field:"reference", sorter:"string", width:150, formatter:"html"},
			{title:"Bibtex", field:"bibtex", formatter:"html", width:30},
			{title:"Title", field:"title", sorter:"string", width:150},
			{title:"Venue", field:"venue", sorter:"string", width:90},
			{title:"Year", field:"year", sorter:"number", width:80},
			{title:"Visual<br>distraction", field:"visual_distraction", sorter:"string", width: 150},
			{title:"Manual<br>distraction", field:"manual_distraction", sorter:"string", width: 150},
			{title:"Cognitive<br>distraction", field:"cognitive_distraction", sorter:"string", width: 150},
			{title:"Visuo-manual<br>distraction", field:"visuomanual_distraction", sorter:"string", width: 150},
			{title:"Observation<br>length", field:"observation", sorter: "string", width: 100},
			{title:"Input", field:"input", sorter: "string", formatter:"html", width: 100},
			{title:"Output", field:"output", sorter:"string", width: 100},
			{title:"Dataset", field:"dataset", sorter:"string", width: 100},
			{title:"Recording<br>conditions", field:"recording_conditions", sorter:"string", width: 100},
			{title:"Location", field:"location", sorter:"string", width: 100},
			{title:"Distraction", field:"distraction", sorter:"string", width: 100},
			{title:"Metrics", field:"metrics", sorter: "string", width: 100}
		],
	});
</script>
	<div>
		<p>Abbreviations</p>
		 <ul>
		  <li>EV - ego-vehicle information</li>
		  <li>PS - physiological signal (e.g. EEG, heart rate, skin conductivity)</li>
		  <li>GC - gaze coordinates (with respect to scene image)</li>
		  <li>GL - glance location (with respect to AOI)</li>
		  <li>HR - head rotation angle</li>
		  <li>IR - near infra-red image</li>
		  <li>TC - thermal image</li>
		  <li>RGB - 3-channel image of driver</li>
		</ul> 
	</div>
	</body>
</html>