<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="assets/css/tabulator/4.9/tabulator.min.css" rel="stylesheet">
		<link href="assets/css/tables.css" rel="stylesheet">
	</head>


	<body>

  <!-- Top navigation -->
<div class="topnav">

<a href="https://github.com/ykotseruba/attention_and_driving">Back to Github</a>
<a href="behavioral_studies.html">Behavioral</a>
<a href="#" class="active">Practical</a>
<a href="datasets_datasets.html">Datasets</a>
<a href="surveys_surveys.html">Surveys</a>


</div> 

<div class="topnav">

<a href="practical_scene_gaze.html">Scene gaze</a>
<a href="practical_in_vehicle_gaze.html">In-vehicle gaze</a>
<a href="#" class="active">Inattention detection</a>
<a href="practical_driver_awareness.html">Driver awareness</a>
<a href="practical_self_driving.html">Self-driving</a>
<a href="practical_factors.html">Factors</a>


</div> 

		<div id="example-table"></div>
						<script type="text/javascript" src="assets/js/tabulator/4.9/tabulator.min.js"></script>
		<script type="text/javascript">
	//sample data
	var tabledata = [
	{reference_link: "https://doi.org/10.1109/ITSC45102.2020.9294686",reference: "<a href=\"https://doi.org/10.1109/ITSC45102.2020.9294686\">2020_ITSC_Dari</a>",title: "Unsupervised Blink Detection and Driver Drowsiness Metrics on Naturalistic Driving Data",venue: "ITSC",year: "2020",inattention_type: "DR",observation: "-",input: "RGB",output: "blink",dataset: "custom: on-road",metrics: "TP, FP, FN, TN, P, R, F1, detection rate"},
{reference_link: "https://doi.org/10.1109/TMC.2019.2962764",reference: "<a href=\"https://doi.org/10.1109/TMC.2019.2962764\">2019_TMC_Fan</a>",title: "GazMon: Eye Gazing Enabled Driving Behavior Monitoring and Prediction",venue: "IEEE Transactions on Mobile Computing",year: "2019",inattention_type: "VD, VMD, CD",observation: "1-5s",input: "RGB",output: "distraction type (1-8s into future, normal, using phone reaching, eating)",dataset: "custom: on-road, sim",metrics: "precision, recall, F-score, accuracy"},
{reference_link: "https://doi.org/10.1109/TITS.2019.2892155",reference: "<a href=\"https://doi.org/10.1109/TITS.2019.2892155\">2019_T-ITS_Chiou</a>",title: "Driver Monitoring Using Sparse Representation With Part-Based Temporal Face Descriptors",venue: "T-ITS",year: "2019",inattention_type: "VD, VMD, CD, DR",observation: "1, 2, 4, 8, 16 frames",input: "RGB",output: "driver status, distraction type",dataset: "custom: on-road, YawDD, DDD",metrics: "specificity, sensitivity, accuracy, f-score."},
{reference_link: "https://doi.org/10.1109/ACCESS.2019.2891971",reference: "<a href=\"https://doi.org/10.1109/ACCESS.2019.2891971\">2019_IEEEAccess_Zhang</a>",title: "Driver Drowsiness Detection using Multi-Channel Second Order Blind Identifications",venue: "IEEE Access",year: "2019",inattention_type: "DR",observation: "10s",input: "RGB, PS",output: "driver status",dataset: "custom: on-road",metrics: "specificity, sensitivity, accuracy, f-score."},
{reference_link: "https://doi.org/10.1109/ACCESS.2019.2936663",reference: "<a href=\"https://doi.org/10.1109/ACCESS.2019.2936663\">2019_IEEEAccess_Deng</a>",title: "Real-Time Driver-Drowsiness Detection System Using Facial Features",venue: "IEEE Access",year: "2019",inattention_type: "DR",observation: "60s",input: "RGB",output: "driver status",dataset: "custom: on-road",metrics: "precision, accuracy"},
{reference_link: "https://doi.org/10.1109/TITS.2018.2883823",reference: "<a href=\"https://doi.org/10.1109/TITS.2018.2883823\">2018_T-ITS_Yu</a>",title: "Driver Drowsiness Detection Using Condition-Adaptive Representation Learning Framework",venue: "T-ITS",year: "2018",inattention_type: "DR",observation: "5 frames",input: "NIR",output: "driver status",dataset: "DDD",metrics: "ROC, precision, detection rate, F-score"},
{reference_link: "https://doi.org/10.1109/IROS.2018.8594305",reference: "<a href=\"https://doi.org/10.1109/IROS.2018.8594305\">2018_IROS_Wang</a>",title: "Real-Time Workload Classification during Driving using HyperNetworks",venue: "IROS",year: "2018",inattention_type: "CD",observation: "5, 10, 15s",input: "GC",output: "driver status",dataset: "custom: sim",metrics: "F-score, Precision, Recall"},
{reference_link: "https://doi.org/10.1049/iet-its.2017.0183",reference: "<a href=\"https://doi.org/10.1049/iet-its.2017.0183\">2017_IET_Zhao</a>",title: "Driver drowsiness detection using facial dynamic fusion information and a DBN",venue: "IET Intelligent Transport Systems",year: "2017",inattention_type: "DR",observation: "1s",input: "RGB",output: "driver status",dataset: "custom: on-road",metrics: "Accuracy"},
{reference_link: "https://doi.org/10.1007/978-3-319-54526-4_9",reference: "<a href=\"https://doi.org/10.1007/978-3-319-54526-4_9\">2017_ACCV_Weng</a>",title: "Driver Drowsiness Detection via a Hierarchical Temporal Deep Belief Network",venue: "ACCV",year: "2017",inattention_type: "DR",observation: "300 frames",input: "NIR",output: "driver status",dataset: "DDD",metrics: "F-score, Accuracy"},
{reference_link: "https://doi.org/10.1007/978-3-319-54526-4_11",reference: "<a href=\"https://doi.org/10.1007/978-3-319-54526-4_11\">2017_ACCV_Shih</a>",title: "MSTN: Multistage Spatial-Temporal Network for Driver Drowsiness Detection",venue: "ACCV",year: "2017",inattention_type: "DR",observation: "50 frames",input: "NIR",output: "driver status",dataset: "DDD",metrics: "F-score, Accuracy"},
{reference_link: "https://doi.org/10.1016/j.trf.2016.09.015",reference: "<a href=\"https://doi.org/10.1016/j.trf.2016.09.015\">2016_TransRes_Munoz</a>",title: "Distinguishing patterns in drivers’ visual attention allocation using Hidden Markov Models",venue: "Transportation Research Part F",year: "2016",inattention_type: "VMD, CD",observation: "-",input: "glance location and duration",output: "driver status",dataset: "custom: on-road",metrics: "average accuracy"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2506602",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2506602\">2016_T-ITS_Liao</a>",title: "Detection of Driver Cognitive Distraction: A Comparison Study of Stop-Controlled Intersection and Speed-Limited Highway",venue: "T-ITS",year: "2016",inattention_type: "CD",observation: "-",input: "EV, GC",output: "driver status",dataset: "custom: sim",metrics: "DR, F1"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2493451",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2493451\">2016_T-ITS_Li</a>",title: "Detecting Drivers’ Mirror-Checking Actions and Its Application to Maneuver and Secondary Task Recognition",venue: "T-ITS",year: "2016",inattention_type: "VD, VMD, CD",observation: "2, 5s",input: "RGB*, EV",output: "distraction type (radio, GPS-following, Phone, picture, conversation)",dataset: "custom: on-road",metrics: "F1"},
{reference_link: "https://doi.org/10.1109/IVS.2016.7535416",reference: "<a href=\"https://doi.org/10.1109/IVS.2016.7535416\">2016_IV_Liao</a>",title: "Detection of Driver Cognitive Distraction: A Comparison Study of Stop-Controlled Intersection and Speed-Limited Highway",venue: "IV",year: "2016",inattention_type: "CD",observation: "2s, 5s",input: "EV, GC, HP",output: "driver status",dataset: "custom: sim",metrics: "DR, F1"},
{reference_link: "https://doi.org/10.1177%2F0018720816647607",reference: "<a href=\"https://doi.org/10.1177%2F0018720816647607\">2016_HumanFactors_Zhang</a>",title: "Evaluation of Strategies for Integrated Classification of Visual-Manual and Cognitive Distractions in Driving",venue: "Human Factors",year: "2016",inattention_type: "VMD, CD",observation: "-",input: "gaze attributes, driving performance, SA measures",output: "driver status",dataset: "custom: sim",metrics: "accuracy, FP"},
{reference_link: "https://doi.org/10.3390/app6050137",reference: "<a href=\"https://doi.org/10.3390/app6050137\">2016_ApplSci_Choi</a>",title: "Tracking a Driver’s Face against Extreme Head Poses and Inference of Drowsiness Using a Hidden Markov Model",venue: "Applied Sciences",year: "2016",inattention_type: "DR",observation: "15 frames",input: "RGB",output: "driver status",dataset: "custom: on-road",metrics: "qualitative"},
{reference_link: "https://doi.org/10.1016/j.aap.2015.09.002",reference: "<a href=\"https://doi.org/10.1016/j.aap.2015.09.002\">2016_AccidentAnalysis_Wang</a>",title: "Driver drowsiness detection based on non-intrusive metrics considering individual specifics",venue: "Accident Analysis and Prevention",year: "2016",inattention_type: "DR",observation: "60s",input: "EV, BL, EC",output: "driver status",dataset: "custom: sim",metrics: "accuracy"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2496157",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2496157\">2015_T-ITS_Liu</a>",title: "Driver Distraction Detection Using Semi-Supervised Machine Learning",venue: "T-ITS",year: "2015",inattention_type: "CD",observation: "10s",input: "HP, GC",output: "driver status",dataset: "custom: on-road",metrics: "specificity, sensitivity, accuracy, f-score."},
{reference_link: "https://doi.org/10.1109/TITS.2014.2324414",reference: "<a href=\"https://doi.org/10.1109/TITS.2014.2324414\">2015_T-ITS_Li</a>",title: "Predicting Perceived Visual and Cognitive Distractions of Drivers With Multimodal Features",venue: "T-ITS",year: "2015",inattention_type: "VD, VMD, CD",observation: "10s",input: "RGB, EV",output: "distraction type",dataset: "custom: on-road",metrics: "precision, recall, F"},
{reference_link: "https://doi.org/10.1109/TITS.2013.2262098",reference: "<a href=\"https://doi.org/10.1109/TITS.2013.2262098\">2013_T-ITS_Mbouna</a>",title: "Visual Analysis of Eye State and Head Pose for Driver Alertness Monitoring",venue: "T-ITS",year: "2013",inattention_type: "D, DR",observation: "120 frames",input: "RGB",output: "driver status",dataset: "custom: on-road",metrics: "TP, FP, FN, TN"},
{reference_link: "http://dx.doi.org/10.1155/2013/263983",reference: "<a href=\"http://dx.doi.org/10.1155/2013/263983\">2013_IJVT_Sigari</a>",title: "A Driver Face Monitoring System for Fatigue andDistraction Detection",venue: "International Journal of Vehicular Technology",year: "2013",inattention_type: "D",observation: "1 frame",input: "RGB",output: "driver status",dataset: "custom: sim, on-road",metrics: "FPR, FNR, precision"},
{reference_link: "http://dx.doi.org/10.1155/2013/648431",reference: "<a href=\"http://dx.doi.org/10.1155/2013/648431\">2013_AdvMechEng_Jin</a>",title: "Driver Sleepiness Detection System Based onEye Movements Variables",venue: "Advances in Mechanical Engineering",year: "2013",inattention_type: "DR",observation: "10s",input: "EC, GC",output: "driver status",dataset: "custom: sim",metrics: "Accuracy"},
{reference_link: "https://doi.org/10.1109/TITS.2012.2187517",reference: "<a href=\"https://doi.org/10.1109/TITS.2012.2187517\">2012_T-ITS_Jimenez</a>",title: "Gaze Fixation System for the Evaluation of Driver Distractions Induced by IVIS",venue: "T-ITS",year: "2012",inattention_type: "VMD, CD",observation: "1 frame",input: "NIR",output: "driver status",dataset: "custom: sim",metrics: "qualitative"},
{reference_link: "https://doi.org/10.1109/ITSC.2012.6338634",reference: "<a href=\"https://doi.org/10.1109/ITSC.2012.6338634\">2012_ITSC_Hirayama</a>",title: "Detection of Driver Distraction based on Temporal Relationshipbetween Eye-Gaze and Peripheral Vehicle Behavior",venue: "ITSC",year: "2012",inattention_type: "CD",observation: "10s",input: "GL",output: "driver status",dataset: "custom: on-road",metrics: "accuracy"},
{reference_link: "https://doi.org/10.1177%2F0018720812446965",reference: "<a href=\"https://doi.org/10.1177%2F0018720812446965\">2012_HumanFactors_Liang</a>",title: "How Dangerous Is Looking Away From the Road? Algorithms Predict Crash Risk From Glance Patterns in Naturalistic Driving",venue: "Human Factors",year: "2012",inattention_type: "D",observation: "3,6,12,24s",input: "GL",output: "driver status",dataset: "100-car NDS",metrics: "correlation"},
{reference_link: "https://doi.org/10.1109/TITS.2011.2119483",reference: "<a href=\"https://doi.org/10.1109/TITS.2011.2119483\">2011_T-ITS_Wollmer</a>",title: "Online Driver Distraction Detection UsingLong Short-Term Memory",venue: "T-ITS",year: "2011",inattention_type: "VMD",observation: "3s",input: "EV, HR",output: "driver status",dataset: "custom: on-road",metrics: "recall, precision, accuracy, F-score"},
{reference_link: "https://doi.org/10.1117/1.3657506",reference: "<a href=\"https://doi.org/10.1117/1.3657506\">2011_OptEng_Jo</a>",title: "Vision-based method for detecting driver drowsiness and distraction in driver monitoring system",venue: "Optical Engineering",year: "2011",inattention_type: "D, DR",observation: "10s",input: "NIR",output: "driver status",dataset: "custom: on-road",metrics: "FP, FN"},
{reference_link: "https://doi.org/10.1049/iet-its.2009.0090",reference: "<a href=\"https://doi.org/10.1049/iet-its.2009.0090\">2011_IET_Flores</a>",title: "Driver drowsiness detection system under infrared illumination for an intelligent vehicle",venue: "IET Intelligent Transport Systems",year: "2011",inattention_type: "D, DR",observation: "1 frame",input: "NIR",output: "driver status",dataset: "custom: on-road",metrics: "correct rate"},
{reference_link: "https://doi.org/10.1007/s11768-010-8043-0",reference: "<a href=\"https://doi.org/10.1007/s11768-010-8043-0\">2010_JCTA_Zhang</a>",title: "A new real-time eye tracking based on nonlinear unscented Kalman filter for monitoring driver fatigue",venue: "Journal of Control Theory Applications",year: "2010",inattention_type: "DR",observation: "6m",input: "NIR",output: "driver status",dataset: "custom: on-road",metrics: "correct rate, average correct"},
{reference_link: "https://doi.org/10.1109/IVS.2010.5548039",reference: "<a href=\"https://doi.org/10.1109/IVS.2010.5548039\">2010_IV_Friedrichs</a>",title: "Camera-based Drowsiness Reference for Driver State Classification under Real Driving Conditions",venue: "IV",year: "2010",inattention_type: "DR",observation: "5 timesteps",input: "EC, HP, EV, BL",output: "driver status",dataset: "custom: on-road",metrics: "correct rate"},
	];

	var table = new Tabulator("#example-table", {
		height:700, // set height of table to enable virtual DOM
		data:tabledata, //load initial data into table
		layout:"fitColumns", //fit columns to width of table (optional)
		columns:[ //Define Table Columns
			{title:"Reference", field:"reference", sorter:"string", width:150, formatter:"html"},
			{title:"Title", field:"title", sorter:"string", width:150},
			{title:"Venue", field:"venue", sorter:"string", width:150},
			{title:"Year", field:"year", sorter:"number", width:80},
			{title:"Inattention<br>type", field:"inattention_type", sorter:"string", width: 80},
			{title:"Observation<br>length", field:"observation", sorter: "string"},
			{title:"Input", field:"input", sorter: "number"},
			{title:"Output", field:"output", sorter:"string"},
			{title:"Dataset", field:"dataset", sorter:"string"},
			{title:"Metrics", field:"metrics", sorter: "string"},
			{title:"Features", field:"features", sorter:"number"},
			{title:"Pipeline", field:"pipeline", sorter: "string"},
		],
	});
</script>
	<div>
		<p>Abbreviations</p>
		 <ul>
		  <li>D - unspecified distraction</li>
		  <li>VD - visual distraction</li>
		  <li>VMD - visual-manual distraction</li>
		  <li>CD - cognitive distraction</li>
		  <li>DR - drowsiness</li>
		  <li>EV - ego-vehicle information</li>
		  <li>PS - physiological signal (e.g. EEG, heart rate, skin conductivity)</li>
		  <li>GC - gaze coordinates (with respect to scene image)</li>
		  <li>GL - glance location (with respect to AOI)</li>
		  <li>HR - head rotation angle</li>
		  <li>NIR - near infra-red image</li>
		  <li>RGB - 3-channel image of driver</li>
		</ul> 
	</div>
	</body>
</html>