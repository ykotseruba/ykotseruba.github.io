<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="assets/css/tabulator/4.9/tabulator.min.css" rel="stylesheet">
		<link href="assets/css/tables.css" rel="stylesheet">
	</head>


	<body>

 <!-- Top navigation -->
<div class="topnav">

<a href="https://github.com/ykotseruba/attention_and_driving">Back to Github</a>
<a href="behavioral_studies.html">Behavioral</a>
<a href="#" class="active">Practical</a>
<a href="datasets_datasets.html">Datasets</a>
<a href="surveys_surveys.html">Surveys</a>


</div> 

<div class="topnav">

<a href="practical_scene_gaze.html">Scene gaze</a>
<a href="practical_in_vehicle_gaze.html">In-vehicle gaze</a>
<a href="practical_distraction_detection.html">Distraction detection</a>
<a href="practical_drowsiness_detection.html">Drowsiness detection</a>
<a href="practical_action_anticipation.html">Action anticipation</a>
<a href="#" class="active">Driver awareness</a>
<a href="practical_self_driving.html">Self-driving</a>
<a href="practical_factors.html">Factors</a>


</div> 

		<div id="example-table"></div>
						<script type="text/javascript" src="assets/js/tabulator/4.9/tabulator.min.js"></script>
		<script type="text/javascript">
	//sample data
	var tabledata = [
	{reference_link: "https://doi.org/10.1109/TITS.2021.3060168",bibtex: "<a href=\"all_bib.html#2021_T-ITS_Ahlstrom\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2021.3060168\">2021_T-ITS_Ahlstrom</a>",title: "Towards a Context-Dependent Multi-Buffer Driver Distraction Detection Algorithm",venue: "T-ITS",year: "2021",code: "-",input: "GD",observation: "2s",output: "warning",objects_of_interest: "-",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IV47402.2020.9304770",bibtex: "<a href=\"all_bib.html#2020_IV_Kim\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IV47402.2020.9304770\">2020_IV_Kim</a>",title: "Toward Real-Time Estimation of Driver Situation Awareness: An Eye-tracking Approach based on Moving Objects of Interest",venue: "IV",year: "2020",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame, 10 s",output: "awareness",objects_of_interest: "pedestrians, vehicles",dataset: "private",recording_conditions: "simulator",metrics: "CC"},
{reference_link: "https://doi.org/10.1109/IROS45743.2020.9341782",bibtex: "<a href=\"all_bib.html#2020_IROS_Dua\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IROS45743.2020.9341782\">2020_IROS_Dua</a>",title: "DGAZE: Driver Gaze Mapping on Road",venue: "IROS",year: "2020",code: "-",input: "D<sup>RGB</sup>",observation: "1 frame",output: "PoG",objects_of_interest: "road users, infrastructure",dataset: "public: DGAZE",recording_conditions: "simulator",metrics: "MAE"},
{reference_link: "https://doi.org/10.1109/TITS.2019.2939676",bibtex: "<a href=\"all_bib.html#2019_T-ITS_Yang\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2019.2939676\">2019_T-ITS_Yang</a>",title: "A Dual-Cameras-Based Driver Gaze Mapping System With an Application on Non-Driving Activities Monitoring",venue: "T-ITS",year: "2019",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1 frame",output: "PoG",objects_of_interest: "-",dataset: "private",recording_conditions: "on-road",metrics: "RMSE"},
{reference_link: "https://doi.org/10.1109/IVS.2019.8814224",bibtex: "<a href=\"all_bib.html#2019_IV_Schwehr\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2019.8814224\">2019_IV_Schwehr</a>",title: "How to Evaluate Object-of-Fixation Detection",venue: "IV",year: "2019",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1 frame",output: "PoG",objects_of_interest: "vehicles",dataset: "public: PRORETA 4",recording_conditions: "on-road",metrics: "P, R, F1"},
{reference_link: "https://doi.org/10.1109/IVS.2019.8814138",bibtex: "<a href=\"all_bib.html#2019_IV_Gillmeier\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2019.8814138\">2019_IV_Gillmeier</a>",title: "Prediction of ego vehicle trajectories based on driver intention and environmental context",venue: "IV",year: "2019",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "continuous",output: "warning",objects_of_interest: "-",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1145/3362743.3362962",bibtex: "<a href=\"all_bib.html#2019_ACM_Ma\">bib</a>",reference: "<a href=\"https://doi.org/10.1145/3362743.3362962\">2019_ACM_Ma</a>",title: "GazeFCW: Filter Collision Warning Triggers by Detecting Driver’s Gaze Area",venue: "Workshop on Machine Learning on Edge in Sensor Systems",year: "2019",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1 frame",output: "warning",objects_of_interest: "pedestrians, vehicles",dataset: "private",recording_conditions: "on-road",metrics: "TP, FP"},
{reference_link: "https://doi.org/10.1109/TITS.2018.2878027",bibtex: "<a href=\"all_bib.html#2018_T-ITS_Tran\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2018.2878027\">2018_T-ITS_Tran</a>",title: "A Human-Vehicle Collaborative Driving Framework for Driver Assistance",venue: "T-ITS",year: "2018",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1.5s",output: "warning",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "simulator",metrics: "RT"},
{reference_link: "https://doi.org/10.1109/IVS.2018.8500532",bibtex: "<a href=\"all_bib.html#2018_IV_Martin\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2018.8500532\">2018_IV_Martin</a>",title: "Object of Fixation Estimation by Joint Analysis of Gaze and Object Dynamics",venue: "IV",year: "2018",code: "-",input: "D<sup>RGB</sup>",observation: "1 fixation",output: "BB+IS",objects_of_interest: "pedestrians, vehicles",dataset: "private",recording_conditions: "simulator",metrics: "PR curve, AP"},
{reference_link: "https://doi.org/10.1109/ITSC.2018.8569655",bibtex: "<a href=\"all_bib.html#2018_ITSC_Schwehr\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2018.8569655\">2018_ITSC_Schwehr</a>",title: "Multi-Hypothesis Multi-Model Driver’s Gaze Target Tracking",venue: "ITSC",year: "2018",code: "-",input: "GD, RD",observation: "1 frame",output: "PoG",objects_of_interest: "pedestrians, cyclists, vehicles",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IVS.2017.7995781",bibtex: "<a href=\"all_bib.html#2017_IV_Zabihi\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2017.7995781\">2017_IV_Zabihi</a>",title: "Detection and Recognition of Traffic Signs Inside the Attentional Visual Field of Drivers",venue: "IV",year: "2017",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "BB, PoG",objects_of_interest: "signs",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/ITSC.2017.8317586",bibtex: "<a href=\"all_bib.html#2017_ITSC_Schwehr\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2017.8317586\">2017_ITSC_Schwehr</a>",title: "Driver’s Gaze Prediction in Dynamic Automotive Scenes",venue: "ITSC",year: "2017",code: "-",input: "GD, RD",observation: "1 frame",output: "PoG",objects_of_interest: "pedestrians, cyclists, vehicles",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IVS.2016.7535425",bibtex: "<a href=\"all_bib.html#2016_IV_Roth\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2016.7535425\">2016_IV_Roth</a>",title: "Driver and Pedestrian Awareness-based Collision Risk Analysis",venue: "IV",year: "2016",code: "-",input: "HP, BB, EV",observation: "1 frame",output: "warning",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/ICRA.2016.7487485",bibtex: "<a href=\"all_bib.html#2016_ICRA_Langner\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ICRA.2016.7487485\">2016_ICRA_Langner</a>",title: "Traffic Awareness Driver Assistance based on Stereovision, Eye-tracking, and Head-Up Display",venue: "ICRA",year: "2016",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "warning",objects_of_interest: "traffic lights",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/ITSC.2015.174",bibtex: "<a href=\"all_bib.html#2015_ITSC_Diederichs\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2015.174\">2015_ITSC_Diederichs</a>",title: "Driver Intention Algorithm for Pedestrian Protection and Automated Emergency Braking Systems",venue: "ITSC",year: "2015",code: "-",input: "S<sup>RGB</sup>",observation: "-",output: "warning",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "simulator",metrics: "-"},
{reference_link: "https://doi.org/10.1109/IVS.2014.6856601",bibtex: "<a href=\"all_bib.html#2014_IV_Zabihi\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2014.6856601\">2014_IV_Zabihi</a>",title: "Frame-Rate Vehicle Detection within the Attentional Visual Area of Drivers",venue: "IV",year: "2014",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1 frame",output: "PoG",objects_of_interest: "vehicles",dataset: "private",recording_conditions: "on-road",metrics: "TP, FP, ROC"},
{reference_link: "https://doi.org/10.1109/IVS.2014.6856450",bibtex: "<a href=\"all_bib.html#2014_IV_Kowsari\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2014.6856450\">2014_IV_Kowsari</a>",title: "Multi-Depth Cross-Calibration of Remote Eye Gaze Trackers and Stereoscopic Scene Systems",venue: "IV",year: "2014",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "PoG",objects_of_interest: "-",dataset: "private",recording_conditions: "on-road",metrics: "AE, RE"},
{reference_link: "https://doi.org/10.1109/IVS.2014.6856474",bibtex: "<a href=\"all_bib.html#2014_IV_Doman\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2014.6856474\">2014_IV_Doman</a>",title: "Estimation of Traffic Sign Visibility Considering Local and Global Features in a Driving Environment",venue: "IV",year: "2014",code: "-",input: "S<sup>RGB</sup>",observation: "6 frames",output: "visibility score",objects_of_interest: "signs",dataset: "private",recording_conditions: "on-road",metrics: "MAE"},
{reference_link: "https://doi.org/10.1109/ITSC.2014.6957880",bibtex: "<a href=\"all_bib.html#2014_ITSC_Tawari_1\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2014.6957880\">2014_ITSC_Tawari_1</a>",title: "Attention Estimation By Simultaneous Analysis of Viewer and View",venue: "ITSC",year: "2014",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1 frame",output: "PoG, BB",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "on-road",metrics: "TP, FP"},
{reference_link: "https://doi.org/10.1109/ITSC.2014.6957881",bibtex: "<a href=\"all_bib.html#2014_ITSC_Tanishige\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2014.6957881\">2014_ITSC_Tanishige</a>",title: "Prediction of Driver’s Pedestrian Detectability by Image Processing Adaptive to Visual Fields of View",venue: "ITSC",year: "2014",code: "-",input: "RGB, BB, GP",observation: "1 frame",output: "detectability",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "simulator",metrics: "MAE"},
{reference_link: "https://openaccess.thecvf.com/content_cvpr_2014/papers/Rezaei_Look_at_the_2014_CVPR_paper.pdf",bibtex: "<a href=\"all_bib.html#2014_CVPR_Rezaei\">bib</a>",reference: "<a href=\"https://openaccess.thecvf.com/content_cvpr_2014/papers/Rezaei_Look_at_the_2014_CVPR_paper.pdf\">2014_CVPR_Rezaei</a>",title: "Look at the Driver, Look at the Road: No Distraction! No Accident!",venue: "CVPR",year: "2014",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "continuous",output: "risk level, warning",objects_of_interest: "vehicles",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IVS.2013.6629443",bibtex: "<a href=\"all_bib.html#2013_IV_Bar\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2013.6629443\">2013_IV_Bar</a>",title: "Seen and Missed Traffic Objects: A Traffic Object-Specific Awareness Estimation",venue: "IV",year: "2013",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "1 frame",output: "BB + IS, warning",objects_of_interest: "vehicles",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IVS.2012.6232220",bibtex: "<a href=\"all_bib.html#2012_IV_George\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2012.6232220\">2012_IV_George</a>",title: "DAARIA: Driver Assistance by Augmented Reality for Intelligent Automobile",venue: "IV",year: "2012",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "warning",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IVS.2012.6232267",bibtex: "<a href=\"all_bib.html#2012_IV_Engel\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2012.6232267\">2012_IV_Engel</a>",title: "Detectability Prediction in Dynamic Scenes for Enhanced Environment Perception",venue: "IV",year: "2012",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "detectability score",objects_of_interest: "pedestrians",dataset: "private",recording_conditions: "on-road",metrics: "TP, FP"},
{reference_link: "https://doi.org/10.1109/ITSC.2012.6338802",bibtex: "<a href=\"all_bib.html#2012_ITSC_Mori\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ITSC.2012.6338802\">2012_ITSC_Mori</a>",title: "Measuring Driver Awareness Based on Correlation Between Gaze Behavior and Risks of Surrounding Vehicles",venue: "ITSC",year: "2012",code: "-",input: "D<sup>RGB</sup>,  S<sup>RGB</sup>",observation: "0.4s",output: "awareness",objects_of_interest: "vehicles",dataset: "private",recording_conditions: "on-road",metrics: "Q"},
{reference_link: "https://doi.org/10.1109/IVS.2011.5940467",bibtex: "<a href=\"all_bib.html#2011_IV_Doman\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2011.5940467\">2011_IV_Doman</a>",title: "Estimation of Traffic Sign Visibility Considering Temporal Environmental Changes for Smart Driver Assistance",venue: "IV",year: "2011",code: "-",input: "S<sup>RGB</sup>",observation: "70 frames",output: "visibility score",objects_of_interest: "signs",dataset: "private",recording_conditions: "on-road",metrics: "MAE"},
{reference_link: "https://doi.org/10.1109/IVS.2010.5548137",bibtex: "<a href=\"all_bib.html#2010_IV_Doman\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2010.5548137\">2010_IV_Doman</a>",title: "Estimation of Traffic Sign Visibility Toward Smart Driver Assistance",venue: "IV",year: "2010",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "visibility score",objects_of_interest: "signs",dataset: "private",recording_conditions: "on-road",metrics: "MAE"},
{reference_link: "https://doi.org/10.1109/CVPRW.2010.5543272",bibtex: "<a href=\"all_bib.html#2010_CVPRW_Doshi\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/CVPRW.2010.5543272\">2010_CVPRW_Doshi</a>",title: "Attention Estimation by Simultaneous Observation of Viewer and View",venue: "CVPRW",year: "2010",code: "-",input: "S<sup>RGB</sup>",observation: "1 frame",output: "saliency map",objects_of_interest: "-",dataset: "private",recording_conditions: "on-road",metrics: "CC, ED"},
	];

	var table = new Tabulator("#example-table", {
		height:700, // set height of table to enable virtual DOM
		data:tabledata, //load initial data into table
		layout:"fitColumns", //fit columns to width of table (optional)
		columns:[ //Define Table Columns
			{title:"Reference", field:"reference", sorter:"string", formatter:"html"},
			{title:"Bibtex", field:"bibtex", formatter:"html", width:30},
			{title:"Title", field:"title", sorter:"string"},
			{title:"Venue", field:"venue", sorter:"string"},
			{title:"Year", field:"year", sorter:"number"},
			{title:"Code", field:"code", sorter:"string", formatter:"html"},
			{title:"Input", field:"input", sorter: "string", formatter:"html"},
			{title:"Observation<br>length", field:"observation", sorter: "string"},
			{title:"Output", field:"output", sorter:"string"},
			{title:"Dataset", field:"dataset", sorter:"string"},
			{title:"Recording<br>conditions", field:"recording_conditions", sorter:"string"},
			{title:"Metrics", field:"metrics", sorter: "string"}
		],
	});
</script>
	<div>
		<p>Abbreviations</p>
		 <ul>
		  <li>RGB - 3-channel image (of driver and/or scene)</li>
		  <li>GD - gaze data</li>
		  <li>RD - range sensor data</li>
		  <li>HP - head pose</li>
		  <li>IS - importance score</li>
		  <li>BB - bounding box</li>
		  <li>PoG - point of gaze</li>
		  <li>Q - qualitative evaluation</li>
		</ul> 
	</div>
	</body>
</html>