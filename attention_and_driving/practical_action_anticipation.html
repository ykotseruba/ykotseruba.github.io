<!DOCTYPE html>
<html lang="en">
	<head>
		<link href="assets/css/tabulator/4.9/tabulator.min.css" rel="stylesheet">
		<link href="assets/css/tables.css" rel="stylesheet">
	</head>


	<body>

 <!-- Top navigation -->
<div class="topnav">

<a href="https://github.com/ykotseruba/attention_and_driving">Back to Github</a>
<a href="behavioral_studies.html">Behavioral</a>
<a href="#" class="active">Practical</a>
<a href="datasets_datasets.html">Datasets</a>
<a href="surveys_surveys.html">Surveys</a>


</div> 

<div class="topnav">

<a href="practical_scene_gaze.html">Scene gaze</a>
<a href="practical_in_vehicle_gaze.html">In-vehicle gaze</a>
<a href="practical_inattention_detection.html">Inattention detection</a>
<a href="#" class="active">Action anticipation</a>
<a href="practical_driver_awareness.html">Driver awareness</a>
<a href="practical_self_driving.html">Self-driving</a>
<a href="practical_factors.html">Factors</a>


</div> 

		<div id="example-table"></div>
						<script type="text/javascript" src="assets/js/tabulator/4.9/tabulator.min.js"></script>
		<script type="text/javascript">
	//sample data
	var tabledata = [
	{reference_link: "https://doi.org/10.1109/TITS.2019.2961928",bibtex: "<a href=\"all_bib.html#2021_T-ITS_Lee\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2019.2961928\">2021_T-ITS_Lee</a>",title: "Continuous Car Driving Intent Detection Using Structural Pattern Recognition",venue: "T-ITS",year: "2021",code: "-",input: "AOI",observation: "6 units",maneuver: "left lane change, right lane change, turn left, turn right",tte: "0.6-1.2s",metrics: "Acc, ROC, Q",dataset: "custom: sim"},
{reference_link: "https://doi.org/10.1109/IVS.2019.8814287",bibtex: "<a href=\"all_bib.html#2019_IV_Akai\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2019.8814287\">2019_IV_Akai</a>",title: "Driving Behavior Modeling Based on Hidden Markov Models with Driver’s Eye-Gaze Measurement and Ego-Vehicle Localization",venue: "IV",year: "2019",code: "-",input: "GC, EV",observation: "0.5s",maneuver: "turn left, turn right, straight",tte: "-",metrics: "Q",dataset: "custom: on-road"},
{reference_link: "https://doi.org/10.1109/TIV.2018.2804160",bibtex: "<a href=\"all_bib.html#2018_TIV_Martin\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TIV.2018.2804160\">2018_TIV_Martin</a>",title: "Dynamics of Driver’s Gaze: Explorations in Behavior Modeling and Maneuver Prediction",venue: "TITS",year: "2018",code: "-",input: "RGB",observation: "5s",maneuver: "left lane change, right lane change, straight",tte: "0-5s",metrics: "R, Q",dataset: "custom: on-road"},
{reference_link: "https://doi.org/10.1109/IVS.2017.7995928",bibtex: "<a href=\"all_bib.html#2017_IV_Martin\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/IVS.2017.7995928\">2017_IV_Martin</a>",title: "Gaze Fixations and Dynamics for Behavior Modeling and Prediction of On-road Driving Maneuvers",venue: "IV",year: "2017",code: "-",input: "RGB",observation: "5s",maneuver: "left lane change, right lane change, straight",tte: "0-2s",metrics: "P, R",dataset: "custom: on-road"},
{reference_link: "https://doi.org/10.1109/ICRA.2016.7487478",bibtex: "<a href=\"all_bib.html#2016_ICRA_Jain \">bib</a>",reference: "<a href=\"https://doi.org/10.1109/ICRA.2016.7487478\">2016_ICRA_Jain </a>",title: "Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture",venue: "ICRA",year: "2016",code: "<a href=\"https://github.com/asheshjain399/RNNexp\">https://github.com/asheshjain399/RNNexp</a>",input: "RGB",observation: "0.8s",maneuver: "left lane change, right lane change, turn left, turn right, straight",tte: "3-4s",metrics: "P, R",dataset: "Brain4Cars"},
{reference_link: "https://doi.org/10.1109/TITS.2015.2493451",bibtex: "<a href=\"all_bib.html#2016_TITS_Li\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TITS.2015.2493451\">2016_TITS_Li</a>",title: "Detecting Drivers' Mirror-Checking Actions and Its Application to Maneuver and Secondary Task Recognition",venue: "T-ITS",year: "2016",code: "-",input: "RGB, EV",observation: "2, 5s",maneuver: "turn left, turn right, straight",tte: "-",metrics: "P, R, F1",dataset: "custom: on-road"},
{reference_link: "https://openaccess.thecvf.com/content_iccv_2015/papers/Jain_Car_That_Knows_ICCV_2015_paper.pdf",bibtex: "<a href=\"all_bib.html#2015_ICCV_Jain\">bib</a>",reference: "<a href=\"https://openaccess.thecvf.com/content_iccv_2015/papers/Jain_Car_That_Knows_ICCV_2015_paper.pdf\">2015_ICCV_Jain</a>",title: "Car that Knows Before You Do: Anticipating Maneuvers via Learning Temporal Driving Models",venue: "ICCV",year: "2015",code: "-",input: "RGB",observation: "0.8s",maneuver: "left lane change, right lane change, turn left, turn right, straight",tte: "3-4s",metrics: "P, R, CM, F1, FP",dataset: "Brain4Cars"},
{reference_link: "https://doi.org/10.1109/TVT.2015.2487826",bibtex: "<a href=\"all_bib.html#2015_TranVehTech_Pugeault\">bib</a>",reference: "<a href=\"https://doi.org/10.1109/TVT.2015.2487826\">2015_TranVehTech_Pugeault</a>",title: "How much of driving is preattentive?",venue: "Transactions on Vehicular Technology",year: "2015",code: "-",input: "RGB",observation: "1 frame",maneuver: "turn left, turn right, brake, clutch, accelerator",tte: "0-50 frames",metrics: "AUC, CM, Q",dataset: "DIPLECS Sweden, DIPLECS Surrey"},
{reference_link: "https://doi.org/10.1007/978-3-642-15567-3_12",bibtex: "<a href=\"all_bib.html#2010_ACCV_Pugeault\">bib</a>",reference: "<a href=\"https://doi.org/10.1007/978-3-642-15567-3_12\">2010_ACCV_Pugeault</a>",title: "Learning Pre-attentive Driving Behaviour from Holistic Visual Features",venue: "ACCV",year: "2010",code: "-",input: "RGB",observation: "1 frame",maneuver: "turn left, turn right, brake, clutch, accelerator",tte: "-",metrics: "AUC, CM, Q",dataset: "DIPLECS Surrey"},
	];

	var table = new Tabulator("#example-table", {
		height:700, // set height of table to enable virtual DOM
		data:tabledata, //load initial data into table
		layout:"fitColumns", //fit columns to width of table (optional)
		columns:[ //Define Table Columns
			{title:"Reference", field:"reference", sorter:"string", formatter:"html"},
			{title:"Bibtex", field:"bibtex", formatter:"html"},
			{title:"Title", field:"title", sorter:"string"},
			{title:"Venue", field:"venue", sorter:"string"},
			{title:"Year", field:"year", sorter:"number"},
			{title:"Code", field:"code", sorter:"string", formatter:"html"},
			{title:"Input", field:"input", sorter: "string"},
			{title:"Observation<br>length", field:"observation", sorter: "string"},	
			{title:"Maneuver", field:"maneuver", sorter: "string"},
			{title:"Time-to-maneuver", field:"tte", sorter: "string"},
			{title:"Metrics", field:"metrics", sorter:"string"},
			{title:"Dataset", field:"dataset", sorter:"string"},
		],
	});
</script>
	<div>
		<p>Abbreviations</p>
		 <ul>
		  <li>RGB - 3-channel image of the scene</li>
		  <li>GC - gaze coordinates</li>
		  <li>EV - ego-vehicle information</li>
		  <li>AOI - areas of interest</li>
		  <li>Acc, P, R - accuracy, precision, recall</li>
		  <li>FP - false positives</li>
		  <li>CM - confusion matrix</li>
		  <li>F1 - F1 score</li>
		  <li>AUC - area under the ROC curve</li>
		  <li>ROC - receiver operating characteristic curve</li>
		  <li>Q - qualitative evaluation</li>
		</ul> 
	</div>
	</body>
</html>